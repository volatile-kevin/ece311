{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECE 311 Lab Final:\n",
    "\n",
    "## Due Date: Sunday, 12/13 @ 11:59PM\n",
    "### Note: a 10% penalty will be applied for each hour your submission is late!\n",
    "\n",
    "This lab final will review the import concepts from the course. Much of this lab should be familiar from previous labs. We encourage you to look back on your previous labs or look at the posted lab solutions on the course website to remind you how to produce your results and evaluate their correctness. Enough talking, let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.io import imread\n",
    "from scipy import signal\n",
    "from pz_plot import pz_plot\n",
    "from scipy.io import wavfile\n",
    "from numpy.random import randn\n",
    "from IPython.display import Audio\n",
    "\n",
    "#Utility function for dB scaling of magnitude spectra\n",
    "def sig2db(mag_spec):\n",
    "    return 20*np.log10(mag_spec)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Building an Edge Detector 2.0\n",
    "\n",
    "In Lab 2 Exercise 4, we built a simple edge detector by applying a high-pass filter along the rows and columns of an image, then combined the two results to create an image of detected edges. In this exercise, we will build a more sophisticated edge detector by adding onto our original design. This improved detector is known as the [Sobel operator](https://en.wikipedia.org/wiki/Sobel_operator).\n",
    "\n",
    "The Sobel operator uses the same intuition of finding horizontal and vertical edges separately, then combining these results to form the image. Let $G_x$ be our resulting image from detecting vertical edges (through the x-axis) and $G_y$ be our resulting image from detecting horizontal edges (through the y-axis, then our final result will be given by\n",
    "\n",
    "$$\n",
    "G[i,j] = \\sqrt{G^2_x[i,j]+G^2_y[i,j]},\n",
    "$$\n",
    "\n",
    "where $G[i,j]$ is the pixel value at row $i$, column $j$. We compute $G_x$ and $G_y$ via convolution as follows:\n",
    "\n",
    "$$\n",
    "G_x = I * \\begin{bmatrix}\n",
    "1 & 0 & -1\\\\\n",
    "\\end{bmatrix} * \\begin{bmatrix}\n",
    "1\\\\\n",
    "2\\\\\n",
    "1\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "G_y = I * \\begin{bmatrix}\n",
    "1\\\\\n",
    "0\\\\\n",
    "-1\\\\\n",
    "\\end{bmatrix} * \\begin{bmatrix}\n",
    "1 & 2 & 1\\\\\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "where $I$ is our original image and $*$ denotes the convolution operator. Note that in the computation of $G_x$ we convolve along the rows with a high-pass filter and convolve along the columns with a low-pass filter, while the computation of $G_y$ reverses this relationship with the same filters.\n",
    "\n",
    "a. Compute the image $G_x$ by performing the two convolutions along the rows and columns, respectively, using $\\textrm{signal.convolve()}$. Plot your resulting image in grayscale. Remember that you should apply the high-pass filter $\\begin{bmatrix}1 & 0 & -1\\end{bmatrix}$ to each **row** and the low-pass filter $\\begin{bmatrix}1 & 2 & 1\\end{bmatrix}$ to each **column**. Also, be sure to use the \"same\" mode when using $\\textrm{signal.convolve()}$.\n",
    "\n",
    "b. Compute the image $G_y$ by performing the two convolutions along the rows and columns, respectively, using $\\textrm{signal.convolve()}$. Plot your resulting image in grayscale. Remember that you should apply the high-pass filter $\\begin{bmatrix}1 & 0 & -1\\end{bmatrix}$ to each **column** and the low-pass filter $\\begin{bmatrix}1 & 2 & 1\\end{bmatrix}$ to each **row**.\n",
    "\n",
    "c. Create final result image $G$ according to the above formulation. Plot your resulting image in grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load test-image.jpg\n",
    "image = imread('test-image.jpg')\n",
    "n_rows,n_cols = image.shape\n",
    "\n",
    "#Code for part a.\n",
    "\n",
    "\n",
    "#Code for part b:\n",
    "\n",
    "\n",
    "#Code for part c:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: LCCDE, Transfer Function, and Impulse Response\n",
    "\n",
    "For each of the following Linear Constant Coefficient Difference Equations (LCCDE), determine the transfer function (numerator and denominator coefficients) in order to plot both the pole-zero plot and impulse response of the system for the requested number of points. **Please plot your impulse responses as a stem plot!** For each system, indicate whether it is BIBO stable, marginally stable, or not BIBO stable and briefly explain your choice.\n",
    "\n",
    "Note: We have provided the $\\textrm{pz_plot}()$ function from Lab 3 to create your pole-zero plots. Refer to Lab 3 for usage of this function. Some other functions of interest you may want to use from Lab 3 will be $\\textrm{signal.dimpulse()}$ and $\\textrm{signal.tf2zpk()}$.\n",
    "\n",
    "a. $y_1[n] = \\frac{1}{3}x[n]-\\frac{1}{9}x[n-1]+x[n-2]-\n",
    "\\frac{1}{9}x[n-3]+\\frac{1}{3}x[n-4],\\quad 0\\leq n < 8$\n",
    "\n",
    "b. $y_2[n] = x[n] + \\frac{1}{4}x[n-2] - y_2[n-1] + 6y_2[n-2],\\quad 0\\leq n < 20$\n",
    "\n",
    "c. $y_3[n] = x[n] - \\frac{1}{2}x[n-2] - y_3[n-2], \\quad 0\\leq n < 20$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for exercise 2:\n",
    "b = [1/3, -1/9, 1, -1/9, 1/3]\n",
    "a = [1, 0, 0, 0, 0]\n",
    "z, p, _ = signal.tf2zpk(b,a)\n",
    "n, y = signal.dimpulse((b,a,1), n=8)\n",
    "h = y[0]\n",
    "\n",
    "pz_plot(z, p, '2a. pole-zero plot')\n",
    "plt.figure()\n",
    "plt.stem(n, h)\n",
    "plt.xlabel('n')\n",
    "plt.ylabel('h[n]')\n",
    "plt.title('Impulse Response of System 1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments for 2.a:\n",
    "\n",
    "\n",
    "Comments for 2.b:\n",
    "\n",
    "\n",
    "Comments for 2.c:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Windows and Spectral Resolution\n",
    "\n",
    "**Note: please specify 512 points for each FFT you take in this problem!**\n",
    "\n",
    "a. Plot the magnitude spectrum (not dB scale) of the following signal using $\\textrm{np.fft.rfft()}$.\n",
    "\n",
    "$$\n",
    "x_1[n] = 0.5\\sin\\left(0.5\\pi n\\right) + 0.05\\sin\\left(0.57\\pi n\\right), \\quad 0\\leq n < 80\n",
    "$$\n",
    "\n",
    "What is happening to the second sinusoid with the smaller magnitude in the frequency domain? Is it easy to locate this frequency peak?\n",
    "\n",
    "b. Fill in the function $\\textrm{modify()}$ below which applies a Hamming window to an input signal. Apply this function to $x_1[n]$ and plot the resulting magnitude spectrum. Is it easier to locate the smaller frequency now?\n",
    "\n",
    "c. Now let's try resolving two close, but equally large frequency peaks in the below signal $x_2[n]$.\n",
    "\n",
    "$$\n",
    "x_2[n] = 0.5\\sin\\left(0.5\\pi n\\right) + 0.5\\sin\\left(0.518\\pi n\\right), \\quad 0\\leq n < 80\n",
    "$$\n",
    "\n",
    "Plot the magnitude spectrum of $x_2[n]$ (not dB scale) before and after applying the $\\textrm{modify()}$ function. Is it easier to differentiate between the two peaks after applying the Hamming window? Why or why not? **Hint: think about the tradeoff between rectangular and Hamming windows!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for part 3.a:\n",
    "\n",
    "\n",
    "#Code for part 3.b:\n",
    "def modify(x):\n",
    "    #apply a hamming window to the signal\n",
    "    \n",
    "    return modified\n",
    "\n",
    "#Code for part 3.c:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments for part 3.a:\n",
    "\n",
    "\n",
    "Comments for part 3.b:\n",
    "\n",
    "\n",
    "Comments for part 3.c:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Chirp Redux\n",
    "\n",
    "For this exercise, we will revisit the chirp activity from Lab 4 but this time with the help of spectrograms to visualize our chirps. The below provided code creates a five second long chirp signal with sampling rate $f_s = 44,100~Hz$ and maximum signal frequency $22,050~Hz$. Recall that the $\\textrm{signal.chirp}$ function linearly sweeps between the requested frequencies over the set time interval. Hint: referring back to Labs 4 and 5 will help with understanding the chirp function and plotting spectrograms, respectively.\n",
    "\n",
    "a. Plot the spectrogram of the original chirp signal we have generated for you.\n",
    "\n",
    "b. Reduce the sampling rate of the original chirp signal by a factor of 5. Plot the resulting spectrogram and explain what you see. If we listened to this audio signal, how many rises and falls would you hear? **Note: you may either create a new chirp signal using the requested lower sampling or perform downsampling without an anti-aliasing filter.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs = 44100 #sampling rate for audio clip in Hz\n",
    "t1 = 5 #make clips 5 seconds\n",
    "t = np.linspace(0,t1,t1*Fs)\n",
    "f0 = 0 #start frequency (Hz)\n",
    "f1 = 22050 #end frequency (Hz)\n",
    "chirp_original = signal.chirp(t,f0 = f0, t1 = t1, f1 = f1)\n",
    "nfft = 1024\n",
    "\n",
    "#Code for part 4.a:\n",
    "\n",
    "\n",
    "#Code for part 4.b:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments for 4.b:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: FIR Filter Design\n",
    "\n",
    "a. Given the audio signal file ``Sound_original.wav``, compute and display the full FFT magnitude spectrum (no dB scale). Try listening to it!\n",
    "\n",
    "b. Now let's assume that we pass this audio signal into a system described as followed.\n",
    "\n",
    "<img src=\"./sys_illus.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "where $x[n]$ is our audio signal, $H(\\omega)$ is an LTI system with impulse response $h[n]$, $d[n]$ is some noise, and $y[n]$ is the ouput. \n",
    "For this question, we want to simulate the ouput result $y[n]$.\n",
    "\n",
    "We only know that the LTI system $H(\\omega)$ is acting like a low-pass filter with a cutoff frequency of $\\frac{\\pi}{3}$. Use $\\textrm{signal.remez()}$ to obtain the impulse response of this system assuming the filter length is $N = 100$ and the transition bandwidth is $\\frac{\\pi}{10}$. Plot magnitude response **on a dB scale** using the provided $\\textrm{sig2db()}$ function. \n",
    "\n",
    "c. Now, we can obtain output $y[n]$ by filtering $x[n]$ with $h[n]$ and adding $d[n]$ after filtering. \n",
    "\n",
    "Here, $d[n]$ is assumed to be additive white Gaussian noise (AWGN). We can create our noise $d[n]$ by typing\n",
    "\n",
    "``d = 1000 * np.random.randn(len(x_filtered))``\n",
    "\n",
    "Compute $y[n]$ by summing your filtered audio signal $x[n]*h[n]$ and d. Try listening to y! Plot the FFT magnitude spectrum of $d[n]$ and the FFT magnitude spectrum of $y[n]$ on separate figures (no dB scale). Judging from these two graphs, do you think the simple filtering methods we have discussed in class will be able to perfectly separate our noise $d[n]$ from the filtered audio $x[n]*h[n]$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs,original = wavfile.read('Sound_original.wav')\n",
    "#Code for 5.a:\n",
    "\n",
    "\n",
    "#Code for 5.b:\n",
    "\n",
    "\n",
    "#Code for 5.c:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments for 5.c:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Instructions:\n",
    "\n",
    "Please place all files in one folder, compress that folder as a zip file, and name the zip file ``netid_labfinal``. Submit your zip file to Compass like previous labs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
